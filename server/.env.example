# Server
PORT=3000
HISTORY_LIMIT=200
ROOMS_UPDATE_THROTTLE_MS=500

# Provider selection: mock | openai | gemini | anthropic
LLM_PROVIDER=mock

# OpenAI (global or per-agent keys)
OPENAI_MODEL=gpt-4o-mini
OPENAI_API_KEY=
OPENAI_API_KEY_ALPHA=
OPENAI_API_KEY_MUSE=
OPENAI_API_KEY_LEO=

# Gemini API (Google AI Studio)
# Model: gemini-2.5-flash-lite | gemini-2.5-flash | gemini-2.5-pro | etc
GEMINI_MODEL=gemini-2.5-flash-lite
GEMINI_API_KEY=
GEMINI_API_KEY_ALPHA=
GEMINI_API_KEY_MUSE=
GEMINI_API_KEY_LEO=

# Anthropic (Claude)
# Model: claude-3-5-sonnet-20240620 | claude-3-haiku-20240307 | claude-3-opus-20240229
ANTHROPIC_MODEL=claude-3-5-sonnet-20240620
ANTHROPIC_API_KEY=
ANTHROPIC_API_KEY_ALPHA=
ANTHROPIC_API_KEY_MUSE=
ANTHROPIC_API_KEY_LEO=

# Alternatively, you may use GOOGLE_API_KEY* names (equivalent)
GOOGLE_API_KEY=
GOOGLE_API_KEY_ALPHA=
GOOGLE_API_KEY_MUSE=
GOOGLE_API_KEY_LEO=

# Agents: enable/disable by id (comma-separated)
# Examples:
#   AGENTS_ENABLED=alpha,muse,leo
#   AGENTS_DISABLED=muse
AGENTS_ENABLED=
AGENTS_DISABLED=

# Safety limits (P0)
# User message constraints
USER_MESSAGE_MAX_CHARS=2000
USER_MIN_INTERVAL_MS=800

# Agent response constraints
AGENT_RESPONSE_MAX_CHARS=100
AGENT_MIN_INTERVAL_MS=1500

# LLM timeout (ms)
LLM_TIMEOUT_MS=15000
